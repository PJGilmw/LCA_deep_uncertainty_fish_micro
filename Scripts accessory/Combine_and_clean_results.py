# -*- coding: utf-8 -*-
"""
Created on Mon Jan  2 22:27:52 2023

@author: Pierre Jouannais, Department of Planning, DCEA, Aalborg University
pijo@plan.aau.dk

"""
'''
This script was used to combine different chunks of the total raw output (500 000 data points in the article), generated by different instances.
Furthermore, it adds a column containing the overall compound content in the microalgal biomass ("bioact_molec_dbio") as it was not kept as an output in the main functions. 
This is a fix performed a posteriori as the datafarames exported in the orginal main functions were too big to store. A lot of variables were then excluded from the export to save space and bioact_molec_dbio was one of them.
We thus recalculate the indicator  bioact_molec_dbio a posteriori.
ITs calculation and export could be coded again in the main functions but this requires some structural changes.

Therefore, even if only chunk of datapoints constitutes the whole output ( no need to recombine), this script can be used to add the "bioact_molec_dbio" column to the table so that it's ready for further processing'

Saves :
    -1 big recombined raw output ready to be further processed for PRIM
    - X recombined raw outputs for all methods, one per method (impact/category) to be easily processed for GSA in Matlab. 
    
    
    
    
 - 1) Choose the chunk to combine and clean/fix  (l.67))
 - 2) Collect list of technosphere FUs 
  -3) Concatenate chunks  " (l.355)
   4) Include MC results for 1 unit of each technosphere input and save raw output for each method for GSA (l. 377)) 
    
'''

import pandas as pd
import decimal
from random import *
import pstats
from itertools import *
from math import*
import csv
import copy
import numpy as np
import random

import datetime
from time import *

import brightway2 as bw

import pickle

import Add_bioact_molec_fix_function as fix

def importpickle(path):
    with open(path, 'rb') as pickle_load:
        obj = pickle.load(pickle_load)
    return obj    



def export_pickle_2(var, name_var, namefolder_in_root):
    '''Saves a pickle in the working directory and
    saves the object in input across python sessions'''

    path_object = "../"+namefolder_in_root+"/"+name_var+".pkl"
    with open(path_object, 'wb') as pickle_file:
        pickle.dump(var, pickle_file, protocol=pickle.HIGHEST_PROTOCOL)





""" 1) Choose the chunk to combine and clean/fix """
# Here for two chunks of results
chunk1 = pd.read_csv("../Outputs Servers/500000/result_AHmicro_12_29_583873_main_chunk1_266800.csv",
                                 sep=";",
                                 header=0,
                                 encoding='unicode_escape',
                                 engine='python')


chunk2 = pd.read_csv("../Outputs Servers/500000/result_AHmicro_12_27_232052_main_chunk2_104832.csv",
                                 sep=";",
                                 header=0,
                                 encoding='unicode_escape',
                                 engine='python')


# Here the corresponding  two chunks of MC iterations for the background ( each technosphere input)

back_mc_1=importpickle("../Background_mc/chunk_Background_mc_12_15_919097_size=266800.pkl")
back_mc_2=importpickle("../Background_mc/chunk_Background_mc_12_15_919097_size=104832.pkl")





# The methods used for the simulations (common to all chunks)
list_meth =[('ReCiPe Midpoint (H)', 'climate change', 'GWP100'), 
            ('ReCiPe Midpoint (H)', 'human toxicity', 'HTPinf'),
            ('ReCiPe Midpoint (H)', 'freshwater ecotoxicity', 'FETPinf'),
             ('TRACI', 'environmental impact', 'eutrophication'),
             ('ReCiPe Midpoint (H)', 'terrestrial ecotoxicity', 'TETPinf'),
             ('ReCiPe Midpoint (H)', 'fossil depletion', 'FDP'),
             ('ReCiPe Midpoint (H)', 'terrestrial acidification', 'TAP100'),
             ('ReCiPe Midpoint (H)', 'freshwater eutrophication', 'FEP'),
             ('ReCiPe Midpoint (H)', 'ozone depletion', 'ODPinf')]





""" 2) Collect list of technosphere FUs 
We need to collect againm the list of the names of the tehcnosphere inputs in the same order as in the output tables that we are gonna combine.
We then need to load brightway again and perfrom the first intialization step as in the code to run the simulations   """
#  CAN BE REPLACED BY A PICKLE IMPORT





# Elemental composition of macronutrients

elemental_contents = pd.read_csv("../Data/elemental_contents.csv",
                                 sep=";",
                                 header=0,
                                 encoding='unicode_escape',
                                 engine='python')

# Cleaning

elemental_contents = elemental_contents.iloc[:, 1:]

def collect_list_FUs():
    
    Techno_Matrix_Fish_loaded = pd.read_excel('../Data/Technosphere_Fish_micro_17_03.xlsx',header=None)
    
    
    Techno_Matrix_Fish_with_names =  np.array(Techno_Matrix_Fish_loaded)
    
    Techno_Matrix_Fish_activities = Techno_Matrix_Fish_with_names[0,1:]
    
    
    # Only amounts, no names
    Techno_Matrix_Fish = Techno_Matrix_Fish_with_names[1:,1:]
    
    if Techno_Matrix_Fish.shape[0]!=Techno_Matrix_Fish.shape[1]:
        
         sys.exit("The Technosphere matrix is not square") 
    
    
    
    # Keep the names and the positions of the activities which are ONLY connected to background activites
    # This means excluding activites starting with "FG_"
    
    filter_names_ok_activities_fish = [name[0:3] !="FG_" for name in Techno_Matrix_Fish_activities]
    filter_names_exclude = [name[0:3] =="FG_" for name in Techno_Matrix_Fish_activities]
    
    
    activities_fish_background = list(compress(Techno_Matrix_Fish_activities, filter_names_ok_activities_fish))
    
    activities_fish_foreground = list(compress(Techno_Matrix_Fish_activities, filter_names_exclude))
    
    
    positions_foreground = [np.where(Techno_Matrix_Fish_activities == act)[0][0] for act in activities_fish_foreground]
    
    # Initialize brightway and calculate LCIA for1 unit of each tehcnosphere inputs
    
    
    bw.projects.set_current('Fish_and_micro_2103') 
    
    
    # Loading Ecoinvent
    Ecoinvent = bw.Database('ecoinvent 3.8 conseq')
    
    
    # Loading foreground database
    
    FISHMIC = bw.Database('AH_combi_1')
    
    
    
    biosphere=bw.Database('biosphere3')
    
    
    
    
    
    
    
    # Loading foreground database
    
    
    MICAH = bw.Database('Micro_for_combi')
    
    # Collecting the foreground activities which are only connected to a background activity for the microalgal compound
    
    
    list_micro_algae_FU = []
    
    list_micro_algae_names = []
    
            
    
    
    for act in MICAH:
        # The original Molecule production activity
        if act['name'] == 'Molecule production PBR':
            # print('oik')
            Molprod = MICAH.get(act['code'])   
    
    
    for act in MICAH:
        # The original wastewater treatment activity
        if act['name'] == 'Wastewater treatment (without electricity) PBR':
            wastewater = MICAH.get(act['code'])
    
    
    LCIdict_micro={}
    
    for exc in list(Molprod.exchanges()):
    
            if exc['type']!='production':
                
                exchange1 = MICAH.get(exc['input'][1])  
                
                name_exchange = exchange1['name']  
                
                list_micro_algae_names.append(name_exchange)
            
                list_micro_algae_FU.append({exchange1 : 1})
                LCIdict_micro[name_exchange]=0
        
        
    

    # Electricity for europe
    
    
    list_electricity_CNTR_FU = []
    
    list_electricity_CNTR_names = []
    
    
    
    for act in Ecoinvent:
                if 'market for electricity' in act['name']:
                    if 'medium voltage' in act['name']:
                        if 'municipal' not in act['name']:
                            if 'label-certified' not in act['name']:
                                if act['location'] in ['ES','SE','IT','PT','GB','FR','GR','CY','IE','DE']:  
                                    print(act)  
                                    list_electricity_CNTR_FU.append({act:1})
                                    list_electricity_CNTR_names.append(act["location"])
    
    
    
    
    #activities_fish_background
    
    for name in activities_fish_background:
    
        print(name)
        FISHMIC.search(name)[0]
        
    list_fish_FU = []
    for name_act in activities_fish_background:
        
        for act in FISHMIC:
            
            if act["name"] == name_act:
                
                list_fish_FU.append({act:1})    
    
    # Necessary
    list_processes_electricity_micro = []
    for exc in list(Molprod.exchanges()):
    #    print(exc)
            if exc['type']!='production':
                
                exchange1 = MICAH.get(exc['input'][1])  
                
                exchange1_name=exchange1['name']
                print(exchange1)
                for exc in list(exchange1.exchanges()):
                    
                   # "MJ heat biogas AD PBR" has an input of the modified anaerobic digestion actvitiy 
                   #from the foreground database, it is not electricity and it can't be found with Ecoinvent.get() 
                    
                    if exc['type']=='technosphere' and exchange1_name!="MJ heat biogas" and exchange1_name!='anaerobic digestion of manure Europe':
                        
                        act_background = Ecoinvent.get(exc['input'][1])  
                        
                        name_background = act_background['name']
                        
                        #print(name_background)
                        if 'electricity' in name_background:
                            print('ok')
                            list_processes_electricity_micro.append(exchange1_name)
              
     
    
    # For natural_gas
    
    
       
    Dict_FU_NG = {}
    
    list_skarka=['ES','SE','IT','PT','GB','FR','GR','CY','IE','DE'] 
    
    
    for loc in list_skarka:
        
        if loc != "CY" and loc!="PT":
            for act in Ecoinvent:
                if "market for natural gas, high pressure" in act["name"] and act["location"] == loc:
                    #print(act)
                    Dict_FU_NG[loc]={Ecoinvent.get(act["code"]):1}
                    
        else:  
            for act in Ecoinvent:
                
                if "market group for natural gas, high pressure" in act["name"]:
                    #print(act["location"])
                
                    if act["location"] == "Europe without Switzerland":
                       # print(act)
                        Dict_FU_NG[loc]={Ecoinvent.get(act["code"]):1}        
                        
                
                
    list_natural_gas_CNTR_FU = [Dict_FU_NG[a] for a in Dict_FU_NG]
            
    
    
    list_natural_gas_CNTR_names=[a+"gas" for a in list_skarka]
    
    
    
    list_FU_combined_names_mc = list_micro_algae_names + activities_fish_background + list_electricity_CNTR_names + list_natural_gas_CNTR_names
    
    
    return list_FU_combined_names_mc
    

# Here the list of FUs
list_FU_names = collect_list_FUs()









""" 3) Concatenate chunks  """


total_output_without_bioact_molec = pd.concat([chunk1,chunk2]) # before recalculating the total content of molecule in the biomass


# Add colum "bioact_molec_dbio"
total_output =fix.add_bioact_molec_dbio(total_output_without_bioact_molec.reset_index(drop="False"),elemental_contents)


""" Save version without MC results for 1 unit of each technosphere input  """

x = datetime.datetime.now()

month=str(x.month)
day=str(x.day)
microsec=str(x.strftime("%f"))
             

name_total_output =  "total_output_for_PRIM" +"_"+month + "_" + day + "_" + microsec
total_output.to_csv("../Outputs/Outputs_recombined/"+str(name_total_output)+'.csv', sep=';', encoding='utf-8')


"""4) Include MC results for 1 unit of each technosphere input and save raw output for each method for GSA """



combined= back_mc_1 + back_mc_2 


list_meth_code =  []

for meth in list_meth:
    list_meth_code.append(meth[-1])
    
 



# We only keep the impact columns in the total output and get rid of unnecessary outputs
col_impacts= [col for col in total_output.columns if any([a in col for a in list_meth_code]) ]




# We save one recombined per method to ease sensitivity analysis and get smaller files
rank=-1
for imp in list_meth_code:
    rank+=1
    
    print(imp)
    
    col_to_remove = [col for col in total_output.columns if col in col_impacts and imp not in col ]
    
    total_output_meth = total_output[[col for col in total_output.columns if col not in col_to_remove]]
    
    total_output_meth["INC-AH_"+imp] = total_output_meth[imp+"INC"] - total_output_meth[imp+"AH"]
    
    
    
    
    # Add background
    list_FU_scores=[a[rank] for a in combined]
        

    
    FUs_df = pd.DataFrame(np.array(list_FU_scores),columns=list_FU_names)

    total_for_meth= pd.concat([total_output_meth.reset_index(drop=True), FUs_df.reset_index(drop=True)],axis=1)


    name_file = month+"_"+day+"_"+microsec+"_"+imp


    total_for_meth.to_csv("../Outputs/Outputs_recombined/"+str(name_file)+'.csv', sep=';', encoding='utf-8')





